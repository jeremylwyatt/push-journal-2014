\section{Three Prediction Problems	}
\label{sec:schema}

\begin{figure*}[t]
\centerline{\includegraphics[width=0.99\textwidth]{three-prediction-problems-1}}
\caption{{\bf (Left panel)} Three types of prediction problem. A robot finger is shown in blue, objects in black, and motions of the finger as dashed lines with arrows. Top row: training data. Bottom row: test data. Each column represents a different problem. Left column: Problem 1 - Action Interpolation. Middle column: Problem 2 - Transfer to novel actions. Right column: Problem 3 - Transfer to novel shapes. {\bf (Right panel)} a modular prediction scheme suitable for solving problem P1. Visual object identification selects a context, and gives object and finger pose, so the associated predictor takes as input the initial starting position and action sequence. Prediction is fed back on itself to produce a multi-step prediction.}
\label{fig:three-prediction-problems}
\end{figure*}

To understand hypotheses H1-H3 consider three corresponding prediction problems laid out in Figure~\ref{fig:three-prediction-problems}: action interpolation (P1), action transfer (P2) and shape transfer (P3). We consider how each might be tackled using either: i) rigid body physics simulation or ii) tabula rasa machine learning. Assume in each case that the shape of the objects and the environment is known.

\noindent {\bf Action Interpolation (P1).} Suppose you have seen some pushes of an object (Figure~\ref{fig:three-prediction-problems}, top row, left column). In some cases the object tipped, in some it slid. Now you are presented with a new push direction (bottom row, left column). The task is to predict the new object motion. To perform this using rigid body mechanics requires knowledge of object and environment parameters such as the mass and frictional coefficients. These could be inferred by fitting the previous motions via parameter search for the rigid body physics simulation. Alternatively generalisation across actions is feasible using tabula rasa machine learning. This is because the experiences span the space within which the new test case falls: there aren't any exactly similar actions, but there are many with similar features. Hence this problem involves {\em action interpolation}.

\noindent {\bf Action Transfer (P2).} The middle column depicts a harder problem since the test action (bottom row) now sits outside the range of training actions. Hence this problem is known as {\em action transfer}. Turning the object around, since it is not symmetric, means that the effects of actions are quite different to before. For example, pushing the top of the L-shaped object will no longer induce it to tip over. This is because the horizontal flap cannot pass through the table: it provides a {\em kinematic constraint} on the motion of the object. This makes action transfer problems challenging for tabula rasa machine learning. Such problems should, however, be no more challenging for rigid body simulation than problem P1, since once an object's parameters are estimated the rigid body simulator can produce predictions for any action.

\noindent {\bf Shape Transfer (P3).} Finally the right hand column requires generalising previous experience (of manipulating two objects) to an object of novel shape. This is challenging for tabula rasa machine learning because small changes in object shape can lead to large changes in behaviour. The problem is also harder than P2 for rigid body simulation, since parameter estimation for mass, frictional coefficients, etc has not been possible on the new object. Thus these parameters must either be guessed or generalised from previous objects.

\subsection{The case for modular prediction learning}

As noted above rigid body simulation is an initially appealing solution to these problems. Rigid body simulators can produce precise, physically plausible predictions about the motion of an object, including predictions for objects of novel shape and for novel actions. Unfortunately it quickly becomes apparent that this creates as well as solves problems. First, rigid body simulators require knowledge of many parameters intrinsic to the object and environment: frictional coefficients, coefficients of restitution, mass, mass distribution etc. These must all be estimated quite precisely from training data to produce an accurate prediction. Thus rigid body simulation does not eliminate the need for learning. Worse, it requires estimation of parameters which are not easily measured autonomously by a robot. Finally, rigid body simulators necessarily use approximate models of phenomena such as friction, the effects of which are extremely hard to accurately model. While this paper is concerned with rigid bodies only, these problems only become worse when the scope is widened to include deformable objects and liquids.

A different approach is required. Tabula rasa learning is one alternative.  Learning a single predictor able to predict for a wide range of object shapes and materials is unrealistic. The variation and complexity is too great for a single learner. A clue as to how to proceed instead comes from computational neuroscience, where models such as MOSAIC employ modular prediction \cite{Haruno_MOSAIC_2008}. Modular means that the overall prediction engine consists of many context specific predictors, where a context is an object, or an object-environment combination. The first advantage of this is that it can be easier to solve many simple learning problems than one complex learning problem. Second, unobservable parameters (frictional coefficients, mass, mass distribution) need not be modelled explicitly but are instead captured implicitly by being associated with a particular context. Whereas MOSAIC couples control and prediction, it avoids real objects (working with simulated mass spring systems). Our work focuses on pure prediction, but for real objects. Our modular prediction scheme uses vision to distinguish the context, by identifying the object shape (Figure~\ref{fig:three-prediction-problems}).

Having explained our overall scheme, we now turn to the mathematical details of how to model robot-object-environment interactions, which will lead in turn to posing the three prediction problems formally.
